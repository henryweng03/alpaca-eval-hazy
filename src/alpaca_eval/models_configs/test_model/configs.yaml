test_model:
  completions_kwargs:
    adapters_name: null
    batch_size: 1
    cache_dir: null
    do_sample: true
    is_fast_tokenizer: true
    max_new_tokens: 2048
    model_kwargs: {}
    model_name: hweng/llama-2-7b-miniguanaco
    remove_ending: null
    temperature: 0.7
    top_p: 1.0
  fn_completions: huggingface_local_completions
  link: null
  pretty_name: test_model
  prompt_template: Mixtral-8x7B-Instruct-v0.1/togetherai_prompt.txt
